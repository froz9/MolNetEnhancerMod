###############################################################################
# Modified MolNetEnhancer Workflow with ClassyFire Integration
# -----------------------------------------------------------------------------
# GOAL:  To assign consensus chemical classifications (Superclass, Class, Subclass)
#        to molecular networks generated by GNPS.
#
# INPUT: 1. GNPS Task ID (downloaded automatically)
#        2. NAP (Network Annotation Propagation) Task ID
#
# LOGIC: 1. Download and align GNPS networking data and NAP in-silico predictions.
#        2. Prioritize "Gold Standard" library matches over NAP predictions.
#        3. Convert SMILES structures to InChIKeys.
#        4. Query the ClassyFire API to get taxonomy hierarchies.
#        5. Compute a "Consensus" class for every connected component (molecular family).
###############################################################################

# --- Dependencies ---
# library(dplyr)       # Data manipulation (filter, select, mutate, joins)
# library(ChemmineR)   # Cheminformatics infrastructure
# library(rinchi)      # Converts SMILES strings to InChIKeys (required for ClassyFire)
# library(classyfireR) # API wrapper to query ClassyFire web server

# --- 1. Data Retrieval ---

# Download the GNPS network Cytoscape data (GraphML and summary tables)
# Note: The task ID here is hardcoded. Ensure this is the correct job for your analysis.
system('curl -d "" "https://gnps.ucsd.edu/ProteoSAFe/DownloadResult?task=b817262cb6114e7295fee4f73b22a3ad&view=download_cytoscape_data" -o GNPS_output_graphML.zip')
system('unzip -d GNPS_output_graphML/ GNPS_output_graphML.zip')

# Define the NAP task identifier (Network Annotation Propagation).
# NAP uses fragmentation trees to predict structures for unknown features.
nap_id = 'c4bb6b8be9e14bdebe87c6ef3abe11f6'

# --- 2. Robust File Path Detection ---

# GNPS output folder structures can vary depending on the workflow version (Classical vs Feature Based).
# This block dynamically finds the 'clusterinfo' (node attributes) and 'DB_result' (library matches) files.
if ('clusterinfo_summary' %in% list.files('GNPS_output_graphML/') & 'DB_result' %in% list.files('GNPS_output_graphML/')) {
    # Standard Classical Molecular Networking layout
    netfile <- paste0('GNPS_output_graphML/clusterinfo_summary/',
                      list.files('GNPS_output_graphML/clusterinfo_summary/')[1])
    gnpslibfile <- paste0('GNPS_output_graphML/DB_result/',
                          list.files('GNPS_output_graphML/DB_result/')[1])
} else if ('clusterinfosummarygroup_attributes_withIDs_withcomponentID' %in% list.files('GNPS_output_graphML/')) {
    # Alternative layout often seen in newer workflow versions
    netfile <- paste0('GNPS_output_graphML/clusterinfosummarygroup_attributes_withIDs_withcomponentID/',
                      list.files('GNPS_output_graphML/clusterinfosummarygroup_attributes_withIDs_withcomponentID/')[1])
    gnpslibfile <- paste0('GNPS_output_graphML/result_specnets_DB/',
                          list.files('GNPS_output_graphML/result_specnets_DB/')[1])
} else {
    # Fallback layout
    netfile <- paste0('GNPS_output_graphML/clusterinfosummary/',
                      list.files('GNPS_output_graphML/clusterinfosummary/')[1])
    gnpslibfile <- paste0('GNPS_output_graphML/result_specnets_DB/',
                          list.files('GNPS_output_graphML/result_specnets_DB/')[1])
}

# --- 3. Loading & Cleaning Annotation Data ---

# Load NAP predictions directly from the ProteoSAFe web server
nap <- read.csv(paste0("http://proteomics2.ucsd.edu/ProteoSAFe/DownloadResultFile?task=", nap_id,
                       "&block=main&file=final_out/node_attributes_table.tsv"), 
                sep = "\t", check.names = F)

# Clean NAP SMILES: 
# NAP often outputs multiple candidates. We take the first one and trim whitespace.
nap$ConsensusSMILES <- sapply(strsplit(nap$ConsensusSMILES, ",\\s*"), function(x) trimws(x[1]))

# Load GNPS Library Matches (The "Gold Standard" annotations)
gnpslib <- read.csv(gnpslibfile, sep = '\t', check.names = F)

# Standardize missing data to R's NA format to prevent errors during merging
gnpslib[gnpslib == ""] <- NA
gnpslib[gnpslib == "N/A"] <- NA
gnpslib[gnpslib == " "] <- NA
gnpslib[gnpslib == "n/a"] <- NA

# Load Network Node Info (Contains 'componentindex' which defines the molecular families)
netfile <- read.csv(netfile, sep = '\t', check.names = F)

# --- 4. Merging & Structure Prioritization ---

# Isolate cluster index and component index (Family ID)
netfile_data <- netfile %>% 
    select(componentindex, `cluster index`) %>% 
    rename(cluster.index = `cluster index`)

# Merge GNPS library hits with Network data
# We use right_join to keep all network nodes, even if they don't have a library match
FinalTable_molnetenhancer <- gnpslib %>% 
    rename(cluster.index = "#Scan#") %>% 
    right_join(netfile_data, by = "cluster.index")

# Add NAP predictions to the table
FinalTable_molnetenhancer <- FinalTable_molnetenhancer %>%
    left_join(nap, by = "cluster.index")

# CRITICAL STEP: Structure Prioritization
# We create 'SMILES_FINAL' using a hierarchy of evidence:
# 1. If we have a GNPS Library match (Smiles.x), use it (High confidence).
# 2. If no Library match but we have a NAP prediction, use NAP (Lower confidence).
FinalTable_molnetenhancer <- FinalTable_molnetenhancer %>% 
    mutate(SMILES_FINAL = case_when(
        is.na(Smiles.x) & !is.na(ConsensusSMILES) ~ ConsensusSMILES,
        !is.na(Smiles.x) & is.na(ConsensusSMILES) ~ Smiles.x,
        !is.na(Smiles.x) & !is.na(ConsensusSMILES) ~ Smiles.x,
        TRUE ~ NA_character_
    ))

# Final cleanup of empty strings
FinalTable_molnetenhancer[FinalTable_molnetenhancer == ""] <- NA

# --- 5. ClassyFire Ontology Retrieval ---

# Extract unique SMILES for API querying to avoid redundant calls
smiles_Classifyre <- FinalTable_molnetenhancer %>% 
    select(cluster.index, SMILES_FINAL) %>% 
    filter(!is.na(SMILES_FINAL)) %>%
    rename(smiles = SMILES_FINAL)

smiles <- (smiles_Classifyre$smiles)

# Convert SMILES to InChIKeys using 'rinchi'. 
# ClassyFire requires InChIKeys as the lookup key.
inchik <- purrr::map(smiles, rinchi::get.inchi.key)

# Query the ClassyFire API
# Note: This step depends on an external server and may take time for large datasets.
Classyfire <- purrr::map(inchik, get_classification)

# Extract Taxonomy Levels from ClassyFire Objects
# These loops iterate through the API return objects to extract specific hierarchy levels.
# tryCatch is used to handle cases where the API returns no classification or fails.

# Extract Superclass (e.g., "Lipids and lipid-like molecules")
Superclass <- Classyfire
for (i in 1:length(inchik)) {  tryCatch({
  Superclass[[i]] <- data.frame(c(Classyfire[[i]]@meta[1],Classyfire[[i]]@classification[2,2]))
},error= function(e) {cat("Error", "\n")})  }
Superclass <- do.call(bind_rows, Filter(Negate(is.null), Superclass))

# Extract Class (e.g., "Glycerophospholipids")
Class <- Classyfire
for (i in 1:length(inchik)) {  tryCatch({
  Class[[i]] <- Classyfire[[i]]@classification[3,2]
},error= function(e) {cat("Error", "\n")})  }
Class <- do.call(bind_rows, Filter(Negate(is.null), Class))

# Extract Subclass (e.g., "Glycerophosphocholines")
Subclass <- Classyfire
for (i in 1:length(inchik)) {  tryCatch({
  Subclass[[i]] <- Classyfire[[i]]@classification[4,2]
},error= function(e) {cat("Error", "\n")})  }
Subclass <- do.call(bind_rows, Filter(Negate(is.null), Subclass))

# Combine retrieved taxonomy into a clean dataframe
Classyfire_result <- transform(cbind(smiles_Classifyre$cluster.index, 
                                     Superclass, Class, Subclass), 
                               inchikey = sub("InChIKey=", "", inchikey))
colnames(Classyfire_result) <- c("cluster.index",
                                 "InChIKey", "Superclass", "Class", "Subclass")

Classyfire_result <- Classyfire_result %>% 
select(cluster.index, Superclass, 
  Class, Subclass)

# Re-merge ClassyFire annotations with the Network Component info
molnetenhancer_df <- Classyfire_result %>%
  mutate(cluster.index = as.integer(cluster.index)) %>%
    right_join(netfile_data, by = "cluster.index")


# --- 6. Consensus Classification Logic ---

# HELPER FUNCTION: highestscore
# Calculates the most frequent taxonomy term within a connected component.
# Returns: The consensus term and the score (percentage of nodes sharing that term).
highestscore <- function(df, chem_level_column) {
  df %>%
    filter(
      !is.na(.data[[chem_level_column]]),
      .data[[chem_level_column]] != "",
      .data[[chem_level_column]] != "NA"
    ) %>%
    group_by(componentindex, .data[[chem_level_column]]) %>%
    summarise(
      count = n(),
      .groups = "drop"
    ) %>%
    group_by(componentindex) %>%
    summarise(
      # Select the term with the max count
      consensus_class = ifelse(n() > 0, .data[[chem_level_column]][which.max(count)], NA_character_),
      # Score = (Frequency of Dominant Term) / (Total Annotated Nodes in Component)
      score = ifelse(n() > 0, max(count) / sum(count), NA),
      .groups = "drop"
    )
}

# MAIN FUNCTION: define_consensus_classes
# Applies the consensus logic and propagates it to all nodes in the family.
define_consensus_classes <- function(data) {
  # Validation step
  required_columns <- c("componentindex", "Superclass", "Class", "Subclass")
  if (!all(required_columns %in% colnames(data))) {
    stop("Input data must contain the columns: componentindex, Superclass, Class, and Subclass.")
  }
  
  # 1. Calculate consensus stats for all levels
  superclass_consensus <- highestscore(data, "Superclass")
  class_consensus <- highestscore(data, "Class")
  subclass_consensus <- highestscore(data, "Subclass")
  
  # 2. Join consensus stats back to the main data
  final <- data %>%
    left_join(superclass_consensus, by = "componentindex") %>%
    rename(Superclass_Consensus = consensus_class, Superclass_Score = score) %>%
    left_join(class_consensus, by = "componentindex") %>%
    rename(Class_Consensus = consensus_class, Class_Score = score) %>%
    left_join(subclass_consensus, by = "componentindex") %>%
    rename(Subclass_Consensus = consensus_class, Subclass_Score = score) %>%
    group_by(componentindex) %>%
    mutate(
      # 3. Propagate: If a node belongs to a component (index != -1), assign the family consensus
      # This effectively "fills in the blanks" for nodes that had no direct annotation
      Superclass_Consensus = ifelse(componentindex != -1, Superclass_Consensus[1], Superclass),
      Class_Consensus = ifelse(componentindex != -1, Class_Consensus[1], Class),
      Subclass_Consensus = ifelse(componentindex != -1, Subclass_Consensus[1], Subclass)
    ) %>%
    mutate(
      # 4. Final Assignment: Overwrite missing original data with the consensus data
      Superclass = ifelse((is.na(Superclass) | Superclass == "" | Superclass == "NA") & !is.na(Superclass_Consensus), Superclass_Consensus, Superclass),
      Class = ifelse((is.na(Class) | Class == "" | Class == "NA") & !is.na(Class_Consensus), Class_Consensus, Class),
      Subclass = ifelse((is.na(Subclass) | Subclass == "" | Subclass == "NA") & !is.na(Subclass_Consensus), Subclass_Consensus, Subclass)
    ) %>%
    ungroup()
  
  return(final)
}

# --- 7. Execution & Export ---

# Run the consensus function
defined_classes <- define_consensus_classes(molnetenhancer_df) %>%
select(1,6,8,10) # Select componentindex and the new consensus columns

# Save Result
write.csv(defined_classes, file.path("Molnetenhancer.csv"), row.names = FALSE)